Metadata-Version: 2.4
Name: shellai
Version: 0.1.0
Summary: AI-powered shell command generation using local models
Home-page: https://github.com/micrictor/shellai
Author: micrictor
License: MIT
Project-URL: Homepage, https://github.com/micrictor/shellai
Project-URL: Repository, https://github.com/micrictor/shellai
Project-URL: Issues, https://github.com/micrictor/shellai/issues
Keywords: ai,shell,command-line,automation,llm
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: System Administrators
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: System :: Shells
Classifier: Topic :: Utilities
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=1.9.0
Requires-Dist: transformers>=4.20.0
Provides-Extra: test
Requires-Dist: pytest>=7.0.0; extra == "test"
Requires-Dist: pyyaml>=6.0; extra == "test"
Requires-Dist: pytest-cov>=4.0.0; extra == "test"
Requires-Dist: pytest-timeout>=2.1.0; extra == "test"
Requires-Dist: pytest-mock>=3.10.0; extra == "test"
Provides-Extra: dev
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Dynamic: home-page
Dynamic: requires-python

## Shellai

Shellai (pronounced shellay) is a command-line interface for getting AI assistance without network calls or a separate interface.
It's built around the idea that I should be able to, in my terminal, simply type `ai, do this thing` and have it generate the command for me.

The name is inspired by a turtle I tripped over on a run on 21 September 2025. That morning, my house had a power outage, so I couldn't get AI assistance to try some file combinations for a firmware analysis I was doing.

I called it "Shellay" (think: Forrest Gump), which free-flow associated to shell AI, and from there to how existing tools like Goose and Gemini CLI were often overkill and certainly not resilient to things like power outages that kill local wired and cellular internet.

Shellai uses local small-language models (SLMs) by default. Your data stays on your machine. Unlike other tools like `shellgpt`, the local inference is built into this tool - no need to turn up an ollama server seperatly.

TODO:

* run daemon with model pre-loaded in memory. Should save like 80% of runtime
* with daemon, build vector search of local manpages
* train "hackerai" with https://github.com/CoolHandSquid/TireFire/blob/TireFire_V4/WeeklyUpdateFiles/23-04-13_21%3A09%3A32.csv


Running notes:

* Fine-tuning Gemma 270M only took like 4 hours on a desktop 4070. Advantages of very small models, I guess.
* GDB abomination. Gemini/ChatGPT both initially told me "can't be done, you need something like tmux send-keys." After bringing up process injection, they insisted "nope, impossible"
* First thought was just "write to the tty device for parent terminal", but while that shows up it's not runnable in the terminal. TIOCSTI requires permissions (could be done w/ setuid/capabilities) and isn't enabled by default on macos.
* YOLO, use frida
